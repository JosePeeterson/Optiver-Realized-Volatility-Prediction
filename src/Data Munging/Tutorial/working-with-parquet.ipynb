{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "purple-thanksgiving",
   "metadata": {
    "papermill": {
     "duration": 0.0095,
     "end_time": "2021-06-09T20:41:51.199867",
     "exception": false,
     "start_time": "2021-06-09T20:41:51.190367",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "[Apache Parquet](https://arrow.apache.org/docs/python/parquet.html) is an efficient columnar storage format. Compared to saving this dataset in csvs using parquet:\n",
    "- Greatly reduces the necessary disk space\n",
    "- Loads the data into Pandas with memory efficient datatypes\n",
    "- Enables fast reads from disk\n",
    "- Allows us to easily work with partitions of the data\n",
    "\n",
    "Pandas has a parquet integration that makes loading data into a dataframe trivial; we'll try that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "smooth-updating",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-06-09T20:41:51.227644Z",
     "iopub.status.busy": "2021-06-09T20:41:51.226973Z",
     "iopub.status.idle": "2021-06-09T20:41:51.230857Z",
     "shell.execute_reply": "2021-06-09T20:41:51.230079Z",
     "shell.execute_reply.started": "2021-06-09T20:36:44.380567Z"
    },
    "papermill": {
     "duration": 0.022595,
     "end_time": "2021-06-09T20:41:51.231041",
     "exception": false,
     "start_time": "2021-06-09T20:41:51.208446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7c65eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C:\\coursera\\Optiver-Realized-Volatility-Prediction\\data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9e452b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\coursera\\Optiver-Realized-Volatility-Prediction\\src\\Data Munging\\Tutorial\\working-with-parquet.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/coursera/Optiver-Realized-Volatility-Prediction/src/Data%20Munging/Tutorial/working-with-parquet.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m book_train \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_parquet(\u001b[39m'\u001b[39;49m\u001b[39mbook_train.parquet/stock_id=0\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/coursera/Optiver-Realized-Volatility-Prediction/src/Data%20Munging/Tutorial/working-with-parquet.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m book_train\n",
      "File \u001b[1;32mc:\\Users\\josepeeterson.er\\Miniconda3\\envs\\optiver\\lib\\site-packages\\pandas\\io\\parquet.py:493\u001b[0m, in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, **kwargs)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[39m@doc\u001b[39m(storage_options\u001b[39m=\u001b[39m_shared_docs[\u001b[39m\"\u001b[39m\u001b[39mstorage_options\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    429\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_parquet\u001b[39m(\n\u001b[0;32m    430\u001b[0m     path: FilePath \u001b[39m|\u001b[39m ReadBuffer[\u001b[39mbytes\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    436\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    437\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[0;32m    438\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    439\u001b[0m \u001b[39m    Load a parquet object from the file path, returning a DataFrame.\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[39m    DataFrame\u001b[39;00m\n\u001b[0;32m    492\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 493\u001b[0m     impl \u001b[39m=\u001b[39m get_engine(engine)\n\u001b[0;32m    495\u001b[0m     \u001b[39mif\u001b[39;00m use_nullable_dtypes \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m lib\u001b[39m.\u001b[39mno_default:\n\u001b[0;32m    496\u001b[0m         msg \u001b[39m=\u001b[39m (\n\u001b[0;32m    497\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe argument \u001b[39m\u001b[39m'\u001b[39m\u001b[39muse_nullable_dtypes\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is deprecated and will be removed \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    498\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39min a future version.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    499\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\josepeeterson.er\\Miniconda3\\envs\\optiver\\lib\\site-packages\\pandas\\io\\parquet.py:60\u001b[0m, in \u001b[0;36mget_engine\u001b[1;34m(engine)\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m     58\u001b[0m             error_msgs \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m - \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(err)\n\u001b[1;32m---> 60\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m     61\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUnable to find a usable engine; \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     62\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtried using: \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpyarrow\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mfastparquet\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     63\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mA suitable version of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     64\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpyarrow or fastparquet is required for parquet \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     65\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msupport.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     66\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTrying to import the above resulted in these errors:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     67\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00merror_msgs\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     68\u001b[0m     )\n\u001b[0;32m     70\u001b[0m \u001b[39mif\u001b[39;00m engine \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpyarrow\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     71\u001b[0m     \u001b[39mreturn\u001b[39;00m PyArrowImpl()\n",
      "\u001b[1;31mImportError\u001b[0m: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet."
     ]
    }
   ],
   "source": [
    "book_train = pd.read_parquet('book_train.parquet/stock_id=0')\n",
    "book_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04c69464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\coursera\\Optiver-Realized-Volatility-Prediction\\src\\Data Munging\\Tutorial\\working-with-parquet.ipynb Cell 5\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/coursera/Optiver-Realized-Volatility-Prediction/src/Data%20Munging/Tutorial/working-with-parquet.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m path \u001b[39min\u001b[39;00m subset_paths:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/coursera/Optiver-Realized-Volatility-Prediction/src/Data%20Munging/Tutorial/working-with-parquet.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(path))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/coursera/Optiver-Realized-Volatility-Prediction/src/Data%20Munging/Tutorial/working-with-parquet.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     book_train \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_parquet(path)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/coursera/Optiver-Realized-Volatility-Prediction/src/Data%20Munging/Tutorial/working-with-parquet.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     book_train\u001b[39m.\u001b[39mtime_id\u001b[39m.\u001b[39mhist()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/coursera/Optiver-Realized-Volatility-Prediction/src/Data%20Munging/Tutorial/working-with-parquet.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\josepeeterson.er\\Miniconda3\\envs\\optiver\\lib\\site-packages\\pandas\\io\\parquet.py:493\u001b[0m, in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, **kwargs)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[39m@doc\u001b[39m(storage_options\u001b[39m=\u001b[39m_shared_docs[\u001b[39m\"\u001b[39m\u001b[39mstorage_options\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    429\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_parquet\u001b[39m(\n\u001b[0;32m    430\u001b[0m     path: FilePath \u001b[39m|\u001b[39m ReadBuffer[\u001b[39mbytes\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    436\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    437\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[0;32m    438\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    439\u001b[0m \u001b[39m    Load a parquet object from the file path, returning a DataFrame.\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[39m    DataFrame\u001b[39;00m\n\u001b[0;32m    492\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 493\u001b[0m     impl \u001b[39m=\u001b[39m get_engine(engine)\n\u001b[0;32m    495\u001b[0m     \u001b[39mif\u001b[39;00m use_nullable_dtypes \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m lib\u001b[39m.\u001b[39mno_default:\n\u001b[0;32m    496\u001b[0m         msg \u001b[39m=\u001b[39m (\n\u001b[0;32m    497\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe argument \u001b[39m\u001b[39m'\u001b[39m\u001b[39muse_nullable_dtypes\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is deprecated and will be removed \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    498\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39min a future version.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    499\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\josepeeterson.er\\Miniconda3\\envs\\optiver\\lib\\site-packages\\pandas\\io\\parquet.py:60\u001b[0m, in \u001b[0;36mget_engine\u001b[1;34m(engine)\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m     58\u001b[0m             error_msgs \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m - \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(err)\n\u001b[1;32m---> 60\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m     61\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUnable to find a usable engine; \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     62\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtried using: \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpyarrow\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mfastparquet\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     63\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mA suitable version of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     64\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpyarrow or fastparquet is required for parquet \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     65\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msupport.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     66\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTrying to import the above resulted in these errors:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     67\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00merror_msgs\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     68\u001b[0m     )\n\u001b[0;32m     70\u001b[0m \u001b[39mif\u001b[39;00m engine \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpyarrow\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     71\u001b[0m     \u001b[39mreturn\u001b[39;00m PyArrowImpl()\n",
      "\u001b[1;31mImportError\u001b[0m: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet."
     ]
    }
   ],
   "source": [
    "import glob\n",
    "subset_paths = glob.glob('book_train.parquet/stock_id=*')\n",
    "for path in subset_paths:\n",
    "    print(type(path))\n",
    "    book_train = pd.read_parquet(path)\n",
    "    book_train.time_id.hist()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42013840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: Could not locate executable g77\n",
      "WARN: Could not locate executable f77\n",
      "WARN: Could not locate executable ifort\n",
      "WARN: Could not locate executable ifl\n",
      "WARN: Could not locate executable f90\n",
      "WARN: Could not locate executable DF\n",
      "WARN: Could not locate executable efl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.link.c.cmodule): install mkl with `conda install mkl-service`: No module named 'mkl'\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing mf6917bb35eaa79d4a20c20b9dc13c0435e656b1bdb67265fed3d06258ff43ef9: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\coursera\\Optiver-Realized-Volatility-Prediction\\src\\Data Munging\\Tutorial\\working-with-parquet.ipynb Cell 6\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/coursera/Optiver-Realized-Volatility-Prediction/src/Data%20Munging/Tutorial/working-with-parquet.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Declare a model in PyMC3\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/coursera/Optiver-Realized-Volatility-Prediction/src/Data%20Munging/Tutorial/working-with-parquet.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mwith\u001b[39;00m pm\u001b[39m.\u001b[39mModel() \u001b[39mas\u001b[39;00m model:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/coursera/Optiver-Realized-Volatility-Prediction/src/Data%20Munging/Tutorial/working-with-parquet.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m# Specify the prior distribution of unknown parameter\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/coursera/Optiver-Realized-Volatility-Prediction/src/Data%20Munging/Tutorial/working-with-parquet.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     θ \u001b[39m=\u001b[39m pm\u001b[39m.\u001b[39;49mBeta(\u001b[39m\"\u001b[39;49m\u001b[39mθ\u001b[39;49m\u001b[39m\"\u001b[39;49m, alpha\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, beta\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/coursera/Optiver-Realized-Volatility-Prediction/src/Data%20Munging/Tutorial/working-with-parquet.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m# Specify the likelihood distribution and condition on the observed data\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/coursera/Optiver-Realized-Volatility-Prediction/src/Data%20Munging/Tutorial/working-with-parquet.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     y_obs \u001b[39m=\u001b[39m pm\u001b[39m.\u001b[39mBinomial(\u001b[39m\"\u001b[39m\u001b[39my_obs\u001b[39m\u001b[39m\"\u001b[39m, n\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, p\u001b[39m=\u001b[39mθ, observed\u001b[39m=\u001b[39mY)\n",
      "File \u001b[1;32mc:\\Users\\josepeeterson.er\\Miniconda3\\envs\\optiver\\lib\\site-packages\\pymc3\\distributions\\distribution.py:124\u001b[0m, in \u001b[0;36mDistribution.__new__\u001b[1;34m(cls, name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    122\u001b[0m     dist \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mdist(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs, shape\u001b[39m=\u001b[39mshape)\n\u001b[0;32m    123\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 124\u001b[0m     dist \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mdist(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    125\u001b[0m \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39mVar(name, dist, data, total_size, dims\u001b[39m=\u001b[39mdims)\n",
      "File \u001b[1;32mc:\\Users\\josepeeterson.er\\Miniconda3\\envs\\optiver\\lib\\site-packages\\pymc3\\distributions\\distribution.py:133\u001b[0m, in \u001b[0;36mDistribution.dist\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    131\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdist\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    132\u001b[0m     dist \u001b[39m=\u001b[39m \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__new__\u001b[39m(\u001b[39mcls\u001b[39m)\n\u001b[1;32m--> 133\u001b[0m     dist\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    134\u001b[0m     \u001b[39mreturn\u001b[39;00m dist\n",
      "File \u001b[1;32mc:\\Users\\josepeeterson.er\\Miniconda3\\envs\\optiver\\lib\\site-packages\\pymc3\\distributions\\continuous.py:1235\u001b[0m, in \u001b[0;36mBeta.__init__\u001b[1;34m(self, alpha, beta, mu, sigma, sd, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1232\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malpha \u001b[39m=\u001b[39m alpha \u001b[39m=\u001b[39m tt\u001b[39m.\u001b[39mas_tensor_variable(floatX(alpha))\n\u001b[0;32m   1233\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbeta \u001b[39m=\u001b[39m beta \u001b[39m=\u001b[39m tt\u001b[39m.\u001b[39mas_tensor_variable(floatX(beta))\n\u001b[1;32m-> 1235\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmean \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malpha \u001b[39m/\u001b[39m (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49malpha \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbeta)\n\u001b[0;32m   1236\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvariance \u001b[39m=\u001b[39m (\n\u001b[0;32m   1237\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malpha \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbeta \u001b[39m/\u001b[39m ((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39malpha \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbeta) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39malpha \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbeta \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m))\n\u001b[0;32m   1238\u001b[0m )\n\u001b[0;32m   1240\u001b[0m assert_negative_support(alpha, \u001b[39m\"\u001b[39m\u001b[39malpha\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mBeta\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\josepeeterson.er\\Miniconda3\\envs\\optiver\\lib\\site-packages\\theano\\tensor\\var.py:101\u001b[0m, in \u001b[0;36m_tensor_py_operators.__add__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__add__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[0;32m    100\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 101\u001b[0m         \u001b[39mreturn\u001b[39;00m theano\u001b[39m.\u001b[39;49mtensor\u001b[39m.\u001b[39;49mbasic\u001b[39m.\u001b[39;49madd(\u001b[39mself\u001b[39;49m, other)\n\u001b[0;32m    102\u001b[0m     \u001b[39m# We should catch the minimum number of exception here.\u001b[39;00m\n\u001b[0;32m    103\u001b[0m     \u001b[39m# Otherwise this will convert error when Theano flags\u001b[39;00m\n\u001b[0;32m    104\u001b[0m     \u001b[39m# compute_test_value is used\u001b[39;00m\n\u001b[0;32m    105\u001b[0m     \u001b[39m# Evidently, we need to catch NotImplementedError\u001b[39;00m\n\u001b[0;32m    106\u001b[0m     \u001b[39m# TypeError from as_tensor_variable are caught in Elemwise.make_node\u001b[39;00m\n\u001b[0;32m    107\u001b[0m     \u001b[39m# Oterwise TensorVariable * SparseVariable won't work!\u001b[39;00m\n\u001b[0;32m    108\u001b[0m     \u001b[39mexcept\u001b[39;00m (\u001b[39mNotImplementedError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[0;32m    109\u001b[0m         \u001b[39m# We must return NotImplemented and not an\u001b[39;00m\n\u001b[0;32m    110\u001b[0m         \u001b[39m# NotImplementedError or raise an NotImplementedError.\u001b[39;00m\n\u001b[0;32m    111\u001b[0m         \u001b[39m# That way python will give a good error message like this\u001b[39;00m\n\u001b[0;32m    112\u001b[0m         \u001b[39m# `TypeError: unsupported operand type(s) for +:\u001b[39;00m\n\u001b[0;32m    113\u001b[0m         \u001b[39m# 'TensorVariable' and 'TensorVariable'`\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\josepeeterson.er\\Miniconda3\\envs\\optiver\\lib\\site-packages\\theano\\graph\\op.py:253\u001b[0m, in \u001b[0;36mOp.__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    250\u001b[0m node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_node(\u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    252\u001b[0m \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mcompute_test_value \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39moff\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 253\u001b[0m     compute_test_value(node)\n\u001b[0;32m    255\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault_output \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    256\u001b[0m     rval \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39moutputs[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault_output]\n",
      "File \u001b[1;32mc:\\Users\\josepeeterson.er\\Miniconda3\\envs\\optiver\\lib\\site-packages\\theano\\graph\\op.py:126\u001b[0m, in \u001b[0;36mcompute_test_value\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m    123\u001b[0m     compute_map[o] \u001b[39m=\u001b[39m [\u001b[39mFalse\u001b[39;00m]\n\u001b[0;32m    125\u001b[0m \u001b[39m# Create a thunk that performs the computation\u001b[39;00m\n\u001b[1;32m--> 126\u001b[0m thunk \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39;49mop\u001b[39m.\u001b[39;49mmake_thunk(node, storage_map, compute_map, no_recycling\u001b[39m=\u001b[39;49m[])\n\u001b[0;32m    127\u001b[0m thunk\u001b[39m.\u001b[39minputs \u001b[39m=\u001b[39m [storage_map[v] \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m node\u001b[39m.\u001b[39minputs]\n\u001b[0;32m    128\u001b[0m thunk\u001b[39m.\u001b[39moutputs \u001b[39m=\u001b[39m [storage_map[v] \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m node\u001b[39m.\u001b[39moutputs]\n",
      "File \u001b[1;32mc:\\Users\\josepeeterson.er\\Miniconda3\\envs\\optiver\\lib\\site-packages\\theano\\graph\\op.py:634\u001b[0m, in \u001b[0;36mCOp.make_thunk\u001b[1;34m(self, node, storage_map, compute_map, no_recycling, impl)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_node(\n\u001b[0;32m    631\u001b[0m     node, storage_map\u001b[39m=\u001b[39mstorage_map, compute_map\u001b[39m=\u001b[39mcompute_map, impl\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mc\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    632\u001b[0m )\n\u001b[0;32m    633\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 634\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmake_c_thunk(node, storage_map, compute_map, no_recycling)\n\u001b[0;32m    635\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mNotImplementedError\u001b[39;00m, MethodNotDefined):\n\u001b[0;32m    636\u001b[0m     \u001b[39m# We requested the c code, so don't catch the error.\u001b[39;00m\n\u001b[0;32m    637\u001b[0m     \u001b[39mif\u001b[39;00m impl \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mc\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\josepeeterson.er\\Miniconda3\\envs\\optiver\\lib\\site-packages\\theano\\graph\\op.py:600\u001b[0m, in \u001b[0;36mCOp.make_c_thunk\u001b[1;34m(self, node, storage_map, compute_map, no_recycling)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDisabling C code for \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m due to unsupported float16\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    599\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mfloat16\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 600\u001b[0m outputs \u001b[39m=\u001b[39m cl\u001b[39m.\u001b[39;49mmake_thunk(\n\u001b[0;32m    601\u001b[0m     input_storage\u001b[39m=\u001b[39;49mnode_input_storage, output_storage\u001b[39m=\u001b[39;49mnode_output_storage\n\u001b[0;32m    602\u001b[0m )\n\u001b[0;32m    603\u001b[0m thunk, node_input_filters, node_output_filters \u001b[39m=\u001b[39m outputs\n\u001b[0;32m    605\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrval\u001b[39m():\n",
      "File \u001b[1;32mc:\\Users\\josepeeterson.er\\Miniconda3\\envs\\optiver\\lib\\site-packages\\theano\\link\\c\\basic.py:1203\u001b[0m, in \u001b[0;36mCLinker.make_thunk\u001b[1;34m(self, input_storage, output_storage, storage_map)\u001b[0m\n\u001b[0;32m   1175\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1176\u001b[0m \u001b[39mCompiles this linker's fgraph and returns a function to perform the\u001b[39;00m\n\u001b[0;32m   1177\u001b[0m \u001b[39mcomputations, as well as lists of storage cells for both the inputs\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1200\u001b[0m \u001b[39m  first_output = ostor[0].data\u001b[39;00m\n\u001b[0;32m   1201\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1202\u001b[0m init_tasks, tasks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_init_tasks()\n\u001b[1;32m-> 1203\u001b[0m cthunk, module, in_storage, out_storage, error_storage \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__compile__(\n\u001b[0;32m   1204\u001b[0m     input_storage, output_storage, storage_map\n\u001b[0;32m   1205\u001b[0m )\n\u001b[0;32m   1207\u001b[0m res \u001b[39m=\u001b[39m _CThunk(cthunk, init_tasks, tasks, error_storage, module)\n\u001b[0;32m   1208\u001b[0m res\u001b[39m.\u001b[39mnodes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnode_order\n",
      "File \u001b[1;32mc:\\Users\\josepeeterson.er\\Miniconda3\\envs\\optiver\\lib\\site-packages\\theano\\link\\c\\basic.py:1138\u001b[0m, in \u001b[0;36mCLinker.__compile__\u001b[1;34m(self, input_storage, output_storage, storage_map)\u001b[0m\n\u001b[0;32m   1136\u001b[0m input_storage \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(input_storage)\n\u001b[0;32m   1137\u001b[0m output_storage \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(output_storage)\n\u001b[1;32m-> 1138\u001b[0m thunk, module \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcthunk_factory(\n\u001b[0;32m   1139\u001b[0m     error_storage,\n\u001b[0;32m   1140\u001b[0m     input_storage,\n\u001b[0;32m   1141\u001b[0m     output_storage,\n\u001b[0;32m   1142\u001b[0m     storage_map,\n\u001b[0;32m   1143\u001b[0m )\n\u001b[0;32m   1144\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m   1145\u001b[0m     thunk,\n\u001b[0;32m   1146\u001b[0m     module,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1155\u001b[0m     error_storage,\n\u001b[0;32m   1156\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\josepeeterson.er\\Miniconda3\\envs\\optiver\\lib\\site-packages\\theano\\link\\c\\basic.py:1634\u001b[0m, in \u001b[0;36mCLinker.cthunk_factory\u001b[1;34m(self, error_storage, in_storage, out_storage, storage_map)\u001b[0m\n\u001b[0;32m   1632\u001b[0m     \u001b[39mfor\u001b[39;00m node \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnode_order:\n\u001b[0;32m   1633\u001b[0m         node\u001b[39m.\u001b[39mop\u001b[39m.\u001b[39mprepare_node(node, storage_map, \u001b[39mNone\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mc\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1634\u001b[0m     module \u001b[39m=\u001b[39m get_module_cache()\u001b[39m.\u001b[39;49mmodule_from_key(key\u001b[39m=\u001b[39;49mkey, lnk\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m)\n\u001b[0;32m   1636\u001b[0m \u001b[39mvars\u001b[39m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minputs \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutputs \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39morphans\n\u001b[0;32m   1637\u001b[0m \u001b[39m# List of indices that should be ignored when passing the arguments\u001b[39;00m\n\u001b[0;32m   1638\u001b[0m \u001b[39m# (basically, everything that the previous call to uniq eliminated)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\josepeeterson.er\\Miniconda3\\envs\\optiver\\lib\\site-packages\\theano\\link\\c\\cmodule.py:1191\u001b[0m, in \u001b[0;36mModuleCache.module_from_key\u001b[1;34m(self, key, lnk)\u001b[0m\n\u001b[0;32m   1189\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1190\u001b[0m     location \u001b[39m=\u001b[39m dlimport_workdir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdirname)\n\u001b[1;32m-> 1191\u001b[0m     module \u001b[39m=\u001b[39m lnk\u001b[39m.\u001b[39;49mcompile_cmodule(location)\n\u001b[0;32m   1192\u001b[0m     name \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39m\u001b[39m__file__\u001b[39m\n\u001b[0;32m   1193\u001b[0m     \u001b[39massert\u001b[39;00m name\u001b[39m.\u001b[39mstartswith(location)\n",
      "File \u001b[1;32mc:\\Users\\josepeeterson.er\\Miniconda3\\envs\\optiver\\lib\\site-packages\\theano\\link\\c\\basic.py:1543\u001b[0m, in \u001b[0;36mCLinker.compile_cmodule\u001b[1;34m(self, location)\u001b[0m\n\u001b[0;32m   1541\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1542\u001b[0m     _logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLOCATION \u001b[39m\u001b[39m{\u001b[39;00mlocation\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1543\u001b[0m     module \u001b[39m=\u001b[39m c_compiler\u001b[39m.\u001b[39;49mcompile_str(\n\u001b[0;32m   1544\u001b[0m         module_name\u001b[39m=\u001b[39;49mmod\u001b[39m.\u001b[39;49mcode_hash,\n\u001b[0;32m   1545\u001b[0m         src_code\u001b[39m=\u001b[39;49msrc_code,\n\u001b[0;32m   1546\u001b[0m         location\u001b[39m=\u001b[39;49mlocation,\n\u001b[0;32m   1547\u001b[0m         include_dirs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mheader_dirs(),\n\u001b[0;32m   1548\u001b[0m         lib_dirs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlib_dirs(),\n\u001b[0;32m   1549\u001b[0m         libs\u001b[39m=\u001b[39;49mlibs,\n\u001b[0;32m   1550\u001b[0m         preargs\u001b[39m=\u001b[39;49mpreargs,\n\u001b[0;32m   1551\u001b[0m     )\n\u001b[0;32m   1552\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1553\u001b[0m     e\u001b[39m.\u001b[39margs \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfgraph),)\n",
      "File \u001b[1;32mc:\\Users\\josepeeterson.er\\Miniconda3\\envs\\optiver\\lib\\site-packages\\theano\\link\\c\\cmodule.py:2557\u001b[0m, in \u001b[0;36mGCC_compiler.compile_str\u001b[1;34m(module_name, src_code, location, include_dirs, lib_dirs, libs, preargs, py_module, hide_symbols)\u001b[0m\n\u001b[0;32m   2555\u001b[0m \u001b[39mopen\u001b[39m(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(location, \u001b[39m\"\u001b[39m\u001b[39m__init__.py\u001b[39m\u001b[39m\"\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mclose()\n\u001b[0;32m   2556\u001b[0m \u001b[39massert\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(lib_filename)\n\u001b[1;32m-> 2557\u001b[0m \u001b[39mreturn\u001b[39;00m dlimport(lib_filename)\n",
      "File \u001b[1;32mc:\\Users\\josepeeterson.er\\Miniconda3\\envs\\optiver\\lib\\site-packages\\theano\\link\\c\\cmodule.py:294\u001b[0m, in \u001b[0;36mdlimport\u001b[1;34m(fullpath, suffix)\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings():\n\u001b[0;32m    293\u001b[0m     warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnumpy.ndarray size changed\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 294\u001b[0m     rval \u001b[39m=\u001b[39m \u001b[39m__import__\u001b[39;49m(module_name, {}, {}, [module_name])\n\u001b[0;32m    295\u001b[0m t1 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m    296\u001b[0m import_time \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m t1 \u001b[39m-\u001b[39m t0\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing mf6917bb35eaa79d4a20c20b9dc13c0435e656b1bdb67265fed3d06258ff43ef9: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "import pymc3 as pm\n",
    "import scipy\n",
    "\n",
    "Y = scipy.stats.bernoulli(0.7).rvs(20)\n",
    "\n",
    "# Declare a model in PyMC3\n",
    "with pm.Model() as model:\n",
    "    # Specify the prior distribution of unknown parameter\n",
    "    θ = pm.Beta(\"θ\", alpha=1, beta=1)\n",
    "\n",
    "    # Specify the likelihood distribution and condition on the observed data\n",
    "    y_obs = pm.Binomial(\"y_obs\", n=1, p=θ, observed=Y)\n",
    "\n",
    "    # Sample from the posterior distri bution\n",
    "    idata = pm.sample(1000, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5e5ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.620244760247978e-08"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "scipy.stats.uniform(0, 1).rvs(1)\n",
    "Y = scipy.stats.bernoulli(0.7).rvs(20)\n",
    "\n",
    "scipy.stats.beta(2, 5).pdf(0.7)*scipy.stats.bernoulli(0.7).pmf(Y).prod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "recovered-halloween",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T20:41:51.252720Z",
     "iopub.status.busy": "2021-06-09T20:41:51.252098Z",
     "iopub.status.idle": "2021-06-09T20:42:13.694177Z",
     "shell.execute_reply": "2021-06-09T20:42:13.695518Z",
     "shell.execute_reply.started": "2021-06-09T20:36:45.299663Z"
    },
    "papermill": {
     "duration": 22.457304,
     "end_time": "2021-06-09T20:42:13.696461",
     "exception": false,
     "start_time": "2021-06-09T20:41:51.239157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>price</th>\n",
       "      <th>size</th>\n",
       "      <th>order_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>1.002301</td>\n",
       "      <td>326</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "      <td>1.002778</td>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>1.002818</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>57</td>\n",
       "      <td>1.003155</td>\n",
       "      <td>121</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>68</td>\n",
       "      <td>1.003646</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123438</th>\n",
       "      <td>32767</td>\n",
       "      <td>471</td>\n",
       "      <td>0.998659</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123439</th>\n",
       "      <td>32767</td>\n",
       "      <td>517</td>\n",
       "      <td>0.998515</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123440</th>\n",
       "      <td>32767</td>\n",
       "      <td>523</td>\n",
       "      <td>0.998563</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123441</th>\n",
       "      <td>32767</td>\n",
       "      <td>542</td>\n",
       "      <td>0.998803</td>\n",
       "      <td>90</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123442</th>\n",
       "      <td>32767</td>\n",
       "      <td>567</td>\n",
       "      <td>0.998547</td>\n",
       "      <td>300</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123443 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        time_id  seconds_in_bucket     price  size  order_count\n",
       "0             5                 21  1.002301   326           12\n",
       "1             5                 46  1.002778   128            4\n",
       "2             5                 50  1.002818    55            1\n",
       "3             5                 57  1.003155   121            5\n",
       "4             5                 68  1.003646     4            1\n",
       "...         ...                ...       ...   ...          ...\n",
       "123438    32767                471  0.998659   200            3\n",
       "123439    32767                517  0.998515    90            1\n",
       "123440    32767                523  0.998563     1            1\n",
       "123441    32767                542  0.998803    90            4\n",
       "123442    32767                567  0.998547   300            3\n",
       "\n",
       "[123443 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade_train = pd.read_parquet('trade_train.parquet/stock_id=0')\n",
    "trade_train\n",
    "\n",
    "# import glob\n",
    "# subset_paths = glob.glob('trade_train.parquet/stock_id=*')\n",
    "# for path in subset_paths:\n",
    "#     print(type(path))\n",
    "#     trade_train = pd.read_parquet(path)\n",
    "#     trade_train.time_id.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-ministry",
   "metadata": {
    "papermill": {
     "duration": 0.009039,
     "end_time": "2021-06-09T20:42:13.720583",
     "exception": false,
     "start_time": "2021-06-09T20:42:13.711544",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "If this data were stored as a csv, the numeric types would all default to the 64 bit versions. Parquet retains the more efficient types I specified while saving the data.\n",
    "\n",
    "**Expect memory usage to spike to roughly double the final dataframe size while parquet loads a file. Consider loading your largest dataset first or using partitions to mitigate this.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "threaded-confidentiality",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T20:42:13.746496Z",
     "iopub.status.busy": "2021-06-09T20:42:13.745428Z",
     "iopub.status.idle": "2021-06-09T20:42:13.829444Z",
     "shell.execute_reply": "2021-06-09T20:42:13.828597Z",
     "shell.execute_reply.started": "2021-06-09T20:37:02.716728Z"
    },
    "papermill": {
     "duration": 0.099719,
     "end_time": "2021-06-09T20:42:13.829669",
     "exception": false,
     "start_time": "2021-06-09T20:42:13.729950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype   \n",
      "---  ------             --------------  -----   \n",
      " 0   time_id            3 non-null      int16   \n",
      " 1   seconds_in_bucket  3 non-null      int16   \n",
      " 2   bid_price1         3 non-null      float32 \n",
      " 3   ask_price1         3 non-null      float32 \n",
      " 4   bid_price2         3 non-null      float32 \n",
      " 5   ask_price2         3 non-null      float32 \n",
      " 6   bid_size1          3 non-null      int32   \n",
      " 7   ask_size1          3 non-null      int32   \n",
      " 8   bid_size2          3 non-null      int32   \n",
      " 9   ask_size2          3 non-null      int32   \n",
      " 10  stock_id           3 non-null      category\n",
      "dtypes: category(1), float32(4), int16(2), int32(4)\n",
      "memory usage: 359.0 bytes\n"
     ]
    }
   ],
   "source": [
    "book_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-acrylic",
   "metadata": {
    "papermill": {
     "duration": 0.012929,
     "end_time": "2021-06-09T20:42:13.855622",
     "exception": false,
     "start_time": "2021-06-09T20:42:13.842693",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The one exception is the `stock_id` column, which has been converted to the category type as it is [the partition column](https://arrow.apache.org/docs/python/parquet.html#reading-from-partitioned-datasets). The parquet files in this dataset are all paritioned by `stock_id` so that it's not necessary to load the entire file at once. In fact, if you examine the parquet files you'll see that they are actually directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "insured-morgan",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T20:42:13.899250Z",
     "iopub.status.busy": "2021-06-09T20:42:13.896874Z",
     "iopub.status.idle": "2021-06-09T20:42:16.269750Z",
     "shell.execute_reply": "2021-06-09T20:42:16.270312Z",
     "shell.execute_reply.started": "2021-06-09T20:37:02.746339Z"
    },
    "papermill": {
     "duration": 2.403426,
     "end_time": "2021-06-09T20:42:16.270500",
     "exception": false,
     "start_time": "2021-06-09T20:42:13.867074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'head' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "! cd ../input/optiver-realized-volatility-prediction/book_train.parquet | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-variation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T20:05:53.346883Z",
     "iopub.status.busy": "2021-06-09T20:05:53.346473Z",
     "iopub.status.idle": "2021-06-09T20:05:53.353962Z",
     "shell.execute_reply": "2021-06-09T20:05:53.352397Z",
     "shell.execute_reply.started": "2021-06-09T20:05:53.346851Z"
    },
    "papermill": {
     "duration": 0.012114,
     "end_time": "2021-06-09T20:42:16.292949",
     "exception": false,
     "start_time": "2021-06-09T20:42:16.280835",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Those are in turn also directories, which would be relevant if the data were partitioned by more than one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "mounted-position",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T20:42:16.324742Z",
     "iopub.status.busy": "2021-06-09T20:42:16.323844Z",
     "iopub.status.idle": "2021-06-09T20:42:17.292774Z",
     "shell.execute_reply": "2021-06-09T20:42:17.293257Z",
     "shell.execute_reply.started": "2021-06-09T20:37:03.828010Z"
    },
    "papermill": {
     "duration": 0.988081,
     "end_time": "2021-06-09T20:42:17.293464",
     "exception": false,
     "start_time": "2021-06-09T20:42:16.305383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c439ef22282f412ba39e9137a3fdabac.parquet\r\n"
     ]
    }
   ],
   "source": [
    "! ls ../input/optiver-realized-volatility-prediction/book_train.parquet/stock_id=0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "particular-robinson",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T20:42:17.316579Z",
     "iopub.status.busy": "2021-06-09T20:42:17.315559Z",
     "iopub.status.idle": "2021-06-09T20:42:17.960685Z",
     "shell.execute_reply": "2021-06-09T20:42:17.961759Z",
     "shell.execute_reply.started": "2021-06-09T20:37:41.034806Z"
    },
    "papermill": {
     "duration": 0.659436,
     "end_time": "2021-06-09T20:42:17.961964",
     "exception": false,
     "start_time": "2021-06-09T20:42:17.302528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 917553 entries, 0 to 917552\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   time_id            917553 non-null  int16  \n",
      " 1   seconds_in_bucket  917553 non-null  int16  \n",
      " 2   bid_price1         917553 non-null  float32\n",
      " 3   ask_price1         917553 non-null  float32\n",
      " 4   bid_price2         917553 non-null  float32\n",
      " 5   ask_price2         917553 non-null  float32\n",
      " 6   bid_size1          917553 non-null  int32  \n",
      " 7   ask_size1          917553 non-null  int32  \n",
      " 8   bid_size2          917553 non-null  int32  \n",
      " 9   ask_size2          917553 non-null  int32  \n",
      "dtypes: float32(4), int16(2), int32(4)\n",
      "memory usage: 31.5 MB\n"
     ]
    }
   ],
   "source": [
    "book_train_0 = pd.read_parquet('../input/optiver-realized-volatility-prediction/book_train.parquet/stock_id=0/c439ef22282f412ba39e9137a3fdabac.parquet')\n",
    "book_train_0.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-prague",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T20:23:35.872424Z",
     "iopub.status.busy": "2021-06-09T20:23:35.871533Z",
     "iopub.status.idle": "2021-06-09T20:23:35.881708Z",
     "shell.execute_reply": "2021-06-09T20:23:35.880548Z",
     "shell.execute_reply.started": "2021-06-09T20:23:35.87237Z"
    },
    "papermill": {
     "duration": 0.008829,
     "end_time": "2021-06-09T20:42:17.980793",
     "exception": false,
     "start_time": "2021-06-09T20:42:17.971964",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Note that because we loaded a single partition, **the partition column was not included**. We could remedy that manually if we need the stock ID or just load a larger subset of the data by passing a list of paths. This will load all of the stock IDs 110-119, reducing memory usesage without implicitly dropping the partition column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "continuous-tracy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T20:42:18.005913Z",
     "iopub.status.busy": "2021-06-09T20:42:18.005208Z",
     "iopub.status.idle": "2021-06-09T20:42:20.663517Z",
     "shell.execute_reply": "2021-06-09T20:42:20.663011Z"
    },
    "papermill": {
     "duration": 2.674135,
     "end_time": "2021-06-09T20:42:20.663662",
     "exception": false,
     "start_time": "2021-06-09T20:42:17.989527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14006182 entries, 0 to 14006181\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Dtype   \n",
      "---  ------             -----   \n",
      " 0   time_id            int16   \n",
      " 1   seconds_in_bucket  int16   \n",
      " 2   bid_price1         float32 \n",
      " 3   ask_price1         float32 \n",
      " 4   bid_price2         float32 \n",
      " 5   ask_price2         float32 \n",
      " 6   bid_size1          int32   \n",
      " 7   ask_size1          int32   \n",
      " 8   bid_size2          int32   \n",
      " 9   ask_size2          int32   \n",
      " 10  stock_id           category\n",
      "dtypes: category(1), float32(4), int16(2), int32(4)\n",
      "memory usage: 494.2 MB\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "subset_paths = glob.glob('../input/optiver-realized-volatility-prediction/book_train.parquet/stock_id=11*/*')\n",
    "book_train_subset = pd.read_parquet(subset_paths)\n",
    "book_train_subset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-vacation",
   "metadata": {
    "papermill": {
     "duration": 0.010374,
     "end_time": "2021-06-09T20:42:20.683541",
     "exception": false,
     "start_time": "2021-06-09T20:42:20.673167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 38.912113,
   "end_time": "2021-06-09T20:42:22.222088",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-09T20:41:43.309975",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
