{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/optimusprime/miniconda3/envs/optiver_linux/lib/python3.10/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n",
      "/home/optimusprime/miniconda3/envs/optiver_linux/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import RepeatedKFold, cross_val_score, TimeSeriesSplit\n",
    "\n",
    "import statsmodels as sm\n",
    "from statsmodels.genmod.generalized_linear_model import GLM\n",
    "\n",
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load main data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get labels of features and target\n",
    "\n",
    "os.chdir('/home/optimusprime/Desktop/peeterson/optiver/Optiver-Realized-Volatility-Prediction/data/liquidity_features')\n",
    "\n",
    "\n",
    "with open('int32_feat_labels.pkl', 'rb') as fp:\n",
    "    int32_feat_labels = pickle.load(fp)\n",
    "with open('int64_feat_labels.pkl', 'rb') as fp:\n",
    "    int64_feat_labels = pickle.load(fp)\n",
    "\n",
    "with open('float32_feat_labels.pkl', 'rb') as fp:\n",
    "    float32_feat_labels = pickle.load(fp)\n",
    "with open('float64_feat_labels.pkl', 'rb') as fp:\n",
    "    float64_feat_labels = pickle.load(fp)\n",
    "\n",
    "with open('target_labels.pkl', 'rb') as fp:\n",
    "    target_labels = pickle.load(fp)\n",
    "\n",
    "\n",
    "\n",
    "os.chdir('/home/optimusprime/Desktop/peeterson/optiver/Optiver-Realized-Volatility-Prediction/data/liquidity_features')\n",
    "with open('train_feat_df_reordered.pkl', 'rb') as fp:\n",
    "    train_feat_df_reordered = pickle.load(fp)\n",
    "\n",
    "df = train_feat_df_reordered.copy()\n",
    "del train_feat_df_reordered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reduce data size to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class train_validate_n_test(object):\n",
    "\n",
    "    def __init__(self,df) -> None:\n",
    "\n",
    "        self.time_id_order = df.loc[:3829,'time_id'].values # select ordered unique time_ids\n",
    "        train_time_id_ind = int(len(self.time_id_order)*0.7)\n",
    "        #train_time_ids = time_id_order[:train_time_id_ind]\n",
    "        test_time_ids = self.time_id_order[train_time_id_ind:]\n",
    "        self.test_df = df[df['time_id'].isin(test_time_ids)]\n",
    "\n",
    "        self.n_folds = 30\n",
    "        folds = TimeSeriesSplit(n_splits=self.n_folds,)# max_train_size=None, gap=0)\n",
    "        train_end_ind = int(len(self.time_id_order)*0.7) # index at 70% of time_ids\n",
    "        self.splits = folds.split( range( train_end_ind ) ) # split 70% train time_ids into n_fold splits\n",
    "\n",
    "        feature_importances = pd.DataFrame()\n",
    "        self.feat_cols_list = int32_feat_labels+int64_feat_labels+float32_feat_labels+float64_feat_labels\n",
    "        feature_importances['feature'] = self.feat_cols_list\n",
    "\n",
    "\n",
    "    #### RMSPE cost function\n",
    "    def rmspe(self,y_true, y_pred):\n",
    "        return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "\n",
    "\n",
    "    def lgbm_RMSPE(self,preds, train_data):\n",
    "        labels = train_data.get_label()\n",
    "        return 'RMSPE', round(self.rmspe(y_true = labels, y_pred = preds),5), False\n",
    "\n",
    "\n",
    "    def nancorr(self,a, b):\n",
    "        v = np.isfinite(a)*np.isfinite(b) > 0\n",
    "        return np.corrcoef(a[v], b[v])[0,1]\n",
    "\n",
    "\n",
    "    def lgbm_train_validate(self,params_lgbm,n_rounds):\n",
    "        rmspe_val_score = []\n",
    "        models= []\n",
    "        test_y_preds = np.zeros(len(self.test_df))\n",
    "\n",
    "        for fold_n, (train_index, valid_index) in enumerate(self.splits):\n",
    "            print('Fold:',fold_n+1)\n",
    "            print('train_index',train_index)\n",
    "            print('valid_index',valid_index)\n",
    "            train_time_ids = self.time_id_order[train_index]\n",
    "            val_time_ids = self.time_id_order[valid_index]\n",
    "            train_df = df[df['time_id'].isin(train_time_ids)]\n",
    "            val_df = df[df['time_id'].isin(val_time_ids)]\n",
    "\n",
    "            X_train = train_df[self.feat_cols_list]\n",
    "            y_train = train_df['target']\n",
    "            X_valid = val_df[self.feat_cols_list]\n",
    "            y_valid = val_df['target']\n",
    "\n",
    "            v1tr = np.exp(X_train['log_wap1_log_price_ret_vol'])\n",
    "            v1v = np.exp(  X_valid['log_wap1_log_price_ret_vol'])\n",
    "            v1ts = np.exp( self.test_df['log_wap1_log_price_ret_vol'])\n",
    "\n",
    "\n",
    "            y_train = y_train\n",
    "            w_train = y_train **-2 * v1tr**2\n",
    "\n",
    "            y_val = y_valid\n",
    "            w_val = y_valid **-2 * v1v**2\n",
    "\n",
    "            dtrain = lgb.Dataset(X_train, label=y_train/v1tr, categorical_feature=int64_feat_labels + int32_feat_labels, weight=w_train)\n",
    "            dvalid = lgb.Dataset(X_valid,   label=  y_val/v1v,   categorical_feature=int64_feat_labels + int32_feat_labels, weight=w_val  )\n",
    "\n",
    "\n",
    "            print('model')\n",
    "            clf = lgb.train(params_lgbm, dtrain, n_rounds, valid_sets = [dtrain, dvalid],feval=self.lgbm_RMSPE,)\n",
    "                    #   verbose_eval= 250,\n",
    "                    #   early_stopping_rounds=500,\n",
    "                      #callbacks=[lgb.early_stopping(stopping_rounds=1), lgb.log_evaluation(period=1)])\n",
    "            models.append(clf)\n",
    "\n",
    "\n",
    "            p = clf.predict(X_valid)*v1v\n",
    "            val_score =  np.mean( ((p-y_val)/y_val)**2 )**0.5\n",
    "            \n",
    "            # full_score += y_val.shape[0]*score**2\n",
    "            \n",
    "            \n",
    "            print('SCORE:', val_score)\n",
    "            print(self.nancorr(       p/v1v ,        y_val/v1v ))\n",
    "            print(self.nancorr(np.log(p/v1v), np.log(y_val/v1v)))\n",
    "\n",
    "            print(self.nancorr(p, y_val))\n",
    "            print(self.nancorr(np.log(p), np.log(y_val)))\n",
    "\n",
    "\n",
    "            test_pred = clf.predict(self.test_df[self.feat_cols_list] )*v1ts\n",
    "            test_y_preds += test_pred/self.n_folds\n",
    "\n",
    "            print(f'split: {fold_n}, val rmspe score is {val_score}')\n",
    "            rmspe_val_score.append(val_score)\n",
    "\n",
    "            #del X_train, X_valid, y_train, y_valid,train_df,val_df,dtrain,dvalid, v1tr, v1v, v1ts  \n",
    "\n",
    "\n",
    "        importances = pd.DataFrame({'Feature': clf.feature_name(), \n",
    "                                    'Importance': sum( [model.feature_importance(importance_type='gain') for model in models] )})\n",
    "    \n",
    "        importances2 = importances.nlargest(40,'Importance', keep='first').sort_values(by='Importance', ascending=True)\n",
    "        importances2[['Importance', 'Feature']].plot(kind = 'barh', x = 'Feature', figsize = (8,6), color = 'blue', fontsize=11);plt.ylabel('Feature', fontsize=12)\n",
    "           \n",
    "            \n",
    "        print(f'rmspe score over {self.n_folds} splits is',np.mean(rmspe_val_score))\n",
    "        \n",
    "        del X_train, X_valid, y_train, y_valid,train_df,val_df,dtrain,dvalid, v1tr, v1v, v1ts\n",
    "        gc.collect()\n",
    "        return np.mean(rmspe_val_score)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def evaluate_predictions(self,model):\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "\n",
    "    def make_predictions(self,best_params,num_round, e_s_r):\n",
    "    \n",
    "        return \n",
    "    \n",
    "\n",
    "    def visualize_tree(self,):\n",
    "        # feature_importances['average'] = feature_importances[[f'fold_{fold_n + 1}' for fold_n in range(folds.n_splits)]].mean(axis=1)\n",
    "        # feature_importances.to_csv('feature_importances.csv')\n",
    "        # plt.figure(figsize=(16, 12))\n",
    "        # sns.barplot(data=feature_importances.sort_values(by='average', ascending=False).head(20), x='average', y='feature')\n",
    "        # plt.title('20 TOP feature importance over {} folds average'.format(folds.n_splits));\n",
    "\n",
    "        # importances = pd.DataFrame({'Feature': model.feature_name(), \n",
    "        #                             'Importance': sum( [model.feature_importance(importance_type='gain') for model in models] )})\n",
    "        # importances2 = importances.nlargest(40,'Importance', keep='first').sort_values(by='Importance', ascending=True)\n",
    "        # importances2[['Importance', 'Feature']].plot(kind = 'barh', x = 'Feature', figsize = (8,6), color = 'blue', fontsize=11);plt.ylabel('Feature', fontsize=12)\n",
    "        \n",
    "        #TODO: #plot decision tree for interpretability\n",
    "\n",
    "        return\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OPTUNA objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    " \n",
    "    #os.chdir(\"c:\\Work\\WORK_PACKAGE\\Demand_forecasting\\BLUESG_Demand_data\\Data-preprocessing_data_generation\")\n",
    "    t_v_t = train_validate_n_test(df)\n",
    "\n",
    "    ######  SET Hyperparameter's range for tuning ######\n",
    "    n_rounds = 5\n",
    "    seed1=11\n",
    "    # Hyperparameters and algorithm parameters are described here\n",
    "\n",
    "    params_lgbm = {\n",
    "            'learning_rate':trial.suggest_float(name='learning_rate', low=0.01, high=0.1,log=True),        \n",
    "            'lambda_l1': trial.suggest_int('lambda_l1', 2, 3),\n",
    "            'lambda_l2': trial.suggest_int('lambda_l2', 5, 6),\n",
    "            'num_leaves': trial.suggest_int(name='lambda_l2', low=80, high=83,step=3),\n",
    "            'min_sum_hessian_in_leaf':  trial.suggest_int(name='lambda_l2', low=20, high=23,step=3),\n",
    "            'feature_fraction': round(trial.suggest_float(name='subsample', low=0.8, high=0.9,step=0.1),1),\n",
    "            'feature_fraction_bynode': round(trial.suggest_float(name='subsample', low=0.8, high=0.80,step=0.1),1),\n",
    "            'bagging_fraction': round(trial.suggest_float(name='subsample', low=0.8, high=0.8,step=0.1),1),\n",
    "            'bagging_freq': trial.suggest_int(name='lambda_l2', low=42, high=45,step=3),\n",
    "            'min_data_in_leaf': trial.suggest_int(name='lambda_l2', low=25, high=28,step=3),\n",
    "            'max_depth': trial.suggest_int('lambda_l2', 6, 7),\n",
    "            'objective': 'regression',\n",
    "            'metric': 'None',\n",
    "            'device':'cpu',\n",
    "            'seed': seed1,\n",
    "            'feature_fraction_seed': seed1,\n",
    "            'bagging_seed': seed1,\n",
    "            'drop_seed': seed1,\n",
    "            'data_random_seed': seed1,\n",
    "            'boosting': 'gbdt',\n",
    "            'verbosity': -1,\n",
    "            'n_jobs':-1,\n",
    "    }\n",
    "\n",
    "\n",
    "    ######  SET Hyperparameter's range for tuning ######\n",
    "\n",
    "    val_avg_error = t_v_t.lgbm_train_validate(params_lgbm,n_rounds)\n",
    "    del t_v_t\n",
    "    return val_avg_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, timeout=12000, n_trials=500)\n",
    "\n",
    "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "    #print(\"Best hyperparameters:\", study.best_params)\n",
    "\n",
    "    fig = optuna.visualization.plot_parallel_coordinate(study)\n",
    "    fig.show()\n",
    "\n",
    "    fig = optuna.visualization.plot_optimization_history(study)\n",
    "    fig.show()\n",
    "\n",
    "    fig = optuna.visualization.plot_slice(study)\n",
    "    fig.show()\n",
    "\n",
    "    fig = optuna.visualization.plot_param_importances(study)\n",
    "    fig.show()\n",
    "\n",
    "    # best_tweedie_variance_power = study.best_params[\"tweedie_variance_power\"]\n",
    "    # best_params = {\"max_depth\": study.best_params[\"max_depth\"],\n",
    "    #         \"eta\": study.best_params[\"eta\"],\n",
    "    #         \"subsample\" : study.best_params[\"subsample\"],\n",
    "    #         \"colsample_bytree\": study.best_params[\"colsample_bytree\"],\n",
    "    #         'eval_metric':'tweedie-nloglik@'+str(best_tweedie_variance_power), ## try using AUC as well.. \n",
    "    #         'tweedie_variance_power': best_tweedie_variance_power,\n",
    "    #         'gamma': study.best_params[\"gamma\"],\n",
    "    #         'reg_alpha': study.best_params[\"reg_alpha\"], \n",
    "    #         'reg_lambda': study.best_params[\"reg_lambda\"],\n",
    "    #         'min_child_weight': study.best_params[\"min_child_weight\"],\n",
    "    #         \"objective\": 'reg:tweedie',\n",
    "    #         }\n",
    "    # early_stopping_rounds = 30\n",
    "    # eval_metric = 'tweedie-nloglik@'+str(best_tweedie_variance_power)\n",
    "    # num_round= 1000\n",
    "\n",
    "    # t_v_t = train_validate_n_test()\n",
    "    # best_model = t_v_t.make_predictions(best_params,num_round, early_stopping_rounds)\n",
    "    # t_v_t.evaluate_predictions(best_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model\n"
     ]
    }
   ],
   "source": [
    "#### LGBM model training\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def nancorr(a, b):\n",
    "    v = np.isfinite(a)*np.isfinite(b) > 0\n",
    "    return np.corrcoef(a[v], b[v])[0,1]\n",
    "\n",
    "def rmspe(y_true, y_pred):\n",
    "    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\n",
    "\n",
    "\n",
    "def feval_RMSPE(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    return 'RMSPE', round(rmspe(y_true = labels, y_pred = preds),5), False\n",
    "\n",
    "\n",
    "seed1=11\n",
    "\n",
    "full_data = df\n",
    "\n",
    "params_lgbm = {\n",
    "        'learning_rate': 0.01,        \n",
    "        'lambda_l1': 4,\n",
    "        'lambda_l2': 7,\n",
    "        'num_leaves': 80,\n",
    "        'min_sum_hessian_in_leaf': 20,\n",
    "        'feature_fraction': 0.8,\n",
    "        'feature_fraction_bynode': 0.8,\n",
    "        'bagging_fraction': 0.9,\n",
    "        'bagging_freq': 42,\n",
    "        'min_data_in_leaf': 25,\n",
    "        'max_depth': 8,\n",
    "        'objective': 'regression',\n",
    "        'metric': 'None',\n",
    "        'device':'cpu',\n",
    "    \n",
    "        'seed': seed1,\n",
    "        'feature_fraction_seed': seed1,\n",
    "        'bagging_seed': seed1,\n",
    "        'drop_seed': seed1,\n",
    "        'data_random_seed': seed1,\n",
    "        'boosting': 'gbdt',\n",
    "        'verbosity': -1,\n",
    "        'n_jobs':-1,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "features_to_consider = int32_feat_labels + float32_feat_labels + int64_feat_labels + float64_feat_labels\n",
    "features_to_consider = list(np.unique(features_to_consider))\n",
    "\n",
    "    \n",
    "gc.collect()\n",
    "\n",
    "n_folds = 4\n",
    "n_rounds = 500\n",
    "\n",
    "kf = RepeatedKFold(n_splits=n_folds, n_repeats=3, random_state=1)\n",
    "\n",
    "#scores_folds[model_name] = []\n",
    "counter = 1\n",
    "\n",
    "u = np.unique(df['time_id'])\n",
    "\n",
    "models= []\n",
    "\n",
    "comb_importances = []\n",
    "\n",
    "cluster_importances = {}\n",
    "\n",
    "\n",
    "for ttids, vtids in kf.split(u):\n",
    "        \n",
    "    train_batch = full_data.loc[full_data['time_id'].isin(u[ttids])].reset_index(drop=True)\n",
    "    val_batch   = full_data.loc[full_data['time_id'].isin(u[vtids])].reset_index(drop=True)\n",
    "\n",
    "\n",
    "    v1t = np.exp(train_batch['log_wap1_log_price_ret_vol'])\n",
    "    v1v = np.exp(  val_batch['log_wap1_log_price_ret_vol'])\n",
    "\n",
    "    X_train = train_batch[features_to_consider]\n",
    "    y_train = train_batch['target'].values\n",
    "    w_train = train_batch['target'].values **-2 * v1t**2\n",
    "\n",
    "    X_val = val_batch[features_to_consider]\n",
    "    y_val = val_batch['target'].values\n",
    "    w_val = val_batch['target'].values **-2 * v1v**2\n",
    "\n",
    "\n",
    "    train_data = lgb.Dataset(X_train, label=y_train/v1t, categorical_feature=int64_feat_labels + int32_feat_labels, weight=w_train)\n",
    "    val_data   = lgb.Dataset(X_val,   label=  y_val/v1v,   categorical_feature=int64_feat_labels + int32_feat_labels, weight=w_val  )\n",
    "\n",
    "    print('model')\n",
    "    model = lgb.train(params_lgbm, \n",
    "                      train_data, \n",
    "                      n_rounds, \n",
    "                      valid_sets=val_data, \n",
    "                      feval=feval_RMSPE,\n",
    "\n",
    "                    #   verbose_eval= 250,\n",
    "                    #   early_stopping_rounds=500,\n",
    "                      callbacks=[lgb.early_stopping(stopping_rounds=500), lgb.log_evaluation(period=250)])\n",
    "\n",
    "    models.append(model)\n",
    "    # all_models.append(model)\n",
    "\n",
    "    p = model.predict(X_val)*v1v\n",
    "    score =  np.mean( ((p-y_val)/y_val)**2 )**0.5\n",
    "    \n",
    "    # full_score += y_val.shape[0]*score**2\n",
    "    \n",
    "    \n",
    "    print('SCORE:', score)\n",
    "    print(nancorr(       p/v1v ,        y_val/v1v ))\n",
    "    print(nancorr(np.log(p/v1v), np.log(y_val/v1v)))\n",
    "\n",
    "    print(nancorr(p, y_val))\n",
    "    print(nancorr(np.log(p), np.log(y_val)))\n",
    "\n",
    "    \n",
    "    # #test_pred = (model.predict(test_df[features_to_consider][test_df[cluster_key]==cluster] )\n",
    "    # #                                                         *np.exp(test_df['vol1'][test_df[cluster_key]==cluster]) )\n",
    "    \n",
    "    # #test_df['target'][test_df[cluster_key]==cluster] += test_pred/n_folds\n",
    "\n",
    "\n",
    "importances = pd.DataFrame({'Feature': model.feature_name(), \n",
    "                            'Importance': sum( [model.feature_importance(importance_type='gain') for model in models] )})\n",
    "\n",
    "\n",
    "importances2 = importances.nlargest(40,'Importance', keep='first').sort_values(by='Importance', ascending=True)\n",
    "importances2[['Importance', 'Feature']].plot(kind = 'barh', x = 'Feature', figsize = (8,6), color = 'blue', fontsize=11);plt.ylabel('Feature', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/optimusprime/miniconda3/envs/optiver_linux/lib/python3.10/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n",
      "/home/optimusprime/miniconda3/envs/optiver_linux/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 36\n",
      "[LightGBM] [Info] Number of data points in the train set: 50, number of used features: 2\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 2 dense feature groups (0.00 MB) transferred to GPU in 0.000740 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 0.520000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm\n",
    "import numpy as np\n",
    "def check_gpu_support():\n",
    "    data = np.random.rand(50, 2)\n",
    "    label = np.random.randint(2, size=50)\n",
    "    train_data = lightgbm.Dataset(data, label=label)\n",
    "    params = {'num_iterations': 1, 'device': 'gpu'}\n",
    "    try:\n",
    "        gbm = lightgbm.train(params, train_set=train_data)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "check_gpu_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/optimusprime/Desktop/peeterson/optiver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optiver_linux",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
